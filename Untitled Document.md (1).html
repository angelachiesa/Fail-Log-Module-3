<!DOCTYPE html><html><head><meta charset="utf-8"><title>Untitled Document.md</title><style></style></head><body id="preview">
<h1><a id="Fail_Log_for_Module_Three_0"></a>Fail Log for Module Three</h1>
<h5><a id="July_24th__July_30th_1"></a>July 24th - July 30th</h5>
<hr>
<h6><a id="Previous_Mistakes_3"></a>Previous Mistakes</h6>
<p>One of last mistakes tasks that I want to improve is creating repositories properly. I didn’t set them up correctly if you look at my list, their are so many of them created. I’m hoping with this week, they will be more organized.</p>
<h6><a id="Readings_6"></a>Readings</h6>
<p>For this week’s annotations, I choose <em>Mining and Mapping the Production of Space A View of the World from Houston</em>. The beginning talks about urbanism so it caught my attention. Although the first paragraph was a bit misleading to the rest, it did get me thinking a bit more about data. One thing in particular that I do mention in my blog post as well is how the author changed his data in accordance to the information he collected. He states, <em>“…I shaped the project around the availability of digitized and machine-readable sources. Accessibility can be a major impediment to digital analysis.”</em> He changed his research to match some of the searchings he found. I found this so strange because it never occured to me that someone would do this. It’s really interesting as to what his research would of concluded had the person kept going with their original thought. Even with less data supporting the route that they intended to go in, it would of created an entirely different project in the end.</p>
<p><a href="https://via.hypothes.is/https://web.stanford.edu/group/spatialhistory/cgi-bin/site/pub.php?id=93">https://via.hypothes.is/https://web.stanford.edu/group/spatialhistory/cgi-bin/site/pub.php?id=93</a></p>
<h1><a id="Exercise_1_11"></a>Exercise 1</h1>
<h3><a id="Gentle_Introduction_to_Regex_12"></a>Gentle Introduction to Regex</h3>
<p>To summarize, the point of the exercise is to ask the computer to search for patterns instead of specific data by matching text. This is known as ‘regular expressions’ or also short for ‘Regex’.<br>
Notes – How to describe a pattern, and the regular expressions will find it<br>
How to search and replace data.<br>
Option 1</p>
<ol>
<li>Shift+backslash (dog|cat) means or</li>
<li>If you want to replace every instance of either cat or dog, with the word animals, you open your ‘find-and-replace box’, put dog|cat and put ‘animal’ in the ‘replace’ box, and hit replace all</li>
<li>Note that it messes most things up and will put “certificate” will become &quot;certifianimale”</li>
<li>&lt;cat&gt; for only cat or &lt;cat|dog&gt; only dog and cat<br>
Option 2</li>
<li>gray|grey</li>
<li>gr(a|e)y</li>
<li>(that dog)|(that cat)</li>
<li>d.g will search for “dig”, “dog”, “dug”, and so forth.</li>
<li>do+g will search for “dog”, “doog”, “dooog”, and so forth.</li>
<li>(do)+g will search for “dog”, “dodog”, “dododog”, and so forth.</li>
<li>d.+g will search for “dried fruits are g”,… because the beginning starts will a d and the end starts with a g</li>
<li>(dogs)( and )(cats) will look for all dogs and cats in the document</li>
</ol>
<h3><a id="Regex_Exercise_31"></a>Regex Exercise</h3>
<ul>
<li>Downloaded a file using curl</li>
<li>curl <a href="http://archive.org/stream/diplomaticcorre33statgoog/diplomaticcorre33statgoog_djvu.txt">http://archive.org/stream/diplomaticcorre33statgoog/diplomaticcorre33statgoog_djvu.txt</a> &gt; texas.txt</li>
<li>put &gt; which pushes the result into a file called texas.txt</li>
<li>TO DELETE LIST OF THINGS<br>
o   ctrl+shift+6<br>
o   hit down, and ctrl +k to delete</li>
</ul>
<ol>
<li>sed comman - identifies text that matches a pattern ---- sed ‘s/old text/new text/g’ filename</li>
<li>and grep command - print the results to the screen ---- grep ‘PATTERN WE WANT’ inputfil</li>
<li>use &gt; outputfile at the end if you want a new file</li>
</ol>
<h4><a id="Step_1_45"></a>Step 1</h4>
<p><strong>Notes</strong><br>
If you were using a text editor on your own computer like, for instance Notepad++, you would press ctrl-f or search-&gt;find to open the find dialogue box. In that box, go to the ‘Replace’ tab, and check the radio box for ‘Regular expression’ at the bottom of the search box.</p>
<p>Goal - We wanted to ~ at the beginning of every line that looked like a reference letter.</p>
<ol>
<li>Go into the dhbox and type (grep ‘\bto\b’ texas.txt)<br>
It is to show all the results on the screen, without werid random words.</li>
<li>Copy and paste some of the text into <a href="http://RegExr.com">RegExr.com</a></li>
<li>type (.+&lt;to&gt;)</li>
<li>now back to DhBox, we put sed -r -i.bak ‘s/(.+\bto\b.+)/~\1/g’ texas.txt<br>
what this means -<br>
-r means extended regex. this saves us from having to ‘escape’ certain characters -i.bak means make a backup of the original input file, in case things go wrong. -‘s/old-pattern/newpattern/g’ is how we find and switch what we’re looking for. the final g means ‘globally’, everywhere in the file texas.txt the filename that we’re looking to change.</li>
<li>this gives us a new file called, texas.txt.bak</li>
<li>when we enter into nano, we can see all the ~ have been created.</li>
</ol>
<h4><a id="Step_2_62"></a>Step 2</h4>
<p>In step 2, we want to remove lines which are not relevant.</p>
<p><strong>Notes</strong></p>
<ol>
<li>If I was using a text ediotr on my computer, the serach string is (\n[^~].+)</li>
<li>\n or \r\n means to search for a new line</li>
<li>[] within those, and the ^ this means to search</li>
<li>the .+ means to search for all the rest of the characters in the line as well</li>
<li>To look at it go, grep ‘~’ texas.txt &gt; index.txt</li>
<li>what this does is, it looks for the ‘~’ lines and puts it into a new file called index.txt which you can access with nano.</li>
</ol>
<h4><a id="Step_3_73"></a>Step 3</h4>
<p>Step 3 is to learn how to transform into CSV format.<br>
So basically, how to put this into a spreadsheet.</p>
<ol>
<li>How to change<br>
~Sam Houston to J. Pinckney Henderson, December 31, 1836 51<br>
to<br>
Sam Houston, J. Pinckney Henderson, December 31 1836</li>
</ol>
<p>Use Regex and type: [0-9]{4}</p>
<p>I guessed that you would use<br>
sed -r -i.bak ‘s/(,)( [0-9]{4})(.+)/~\1/g’ texas.txt<br>
and the correct answer is.<br>
sed -r -i.bak ‘s/(,)( [0-9]{4})(.+)/\2/g’ index.txt</p>
<p>I assume that the file was changed to index for something else, not 100% sure why the 2, however it makes me happy that even though I didn’t do it correctly, I was close to getting the command.</p>
<h4><a id="Step_4_91"></a>Step 4</h4>
<p>To delete the tildes, type: sed -r -i.bak ‘s/~//g’ index.txt</p>
<h4><a id="Step_5_93"></a>Step 5</h4>
<p>To seperate senders and recivers, sed -r -i.bak ‘s/(\b to \b)/,/g’ index.txt</p>
<h4><a id="Step_6_96"></a>Step 6</h4>
<p>Cleaned up the file.</p>
<blockquote>
<p>Reflection<br>
I felt pretty good overall with this exercise. It took me the shortest time out of all of them. I remember I had a lot of trouble but I think because I did them slowely and repeated them to make sure I knew what I was doing, I definatly did this one in a short amount of time.</p>
</blockquote>
<h1><a id="Exercise_2_102"></a>Exercise 2</h1>
<p>Could install Refine okay. Had to install Java first, but things went smoothly.</p>
<p>I realized that I didn’t do the first exercise right. I followed the instructions when it came to adding “Sender, Recipient, Date”, However when it was put into Openfile, it didn’t show them as separate columns, but as one. I decided to ask in Slack my issue and just go along with the tutorial regardless. It didn’t seem to mess up how to do the tutorial as the instructions are the same for each column.</p>
<p>** Notes**<br>
How to clean up text using Open File.</p>
<ol>
<li>left of “Sender” in OpenRefine and select Facet-&gt;Text Facet</li>
<li>“Sender” facet box on the left-hand side, click on the button labeled “Cluster”</li>
<li>check the box to the right in the ‘Merge’ column and click the ‘Merge Selected &amp; Re-Cluster’ button below.</li>
<li>click the arrow next to “Sender” and select ‘Edit Cells-&gt;Common transforms-&gt;Trim leading and trailing whitespace’.</li>
</ol>
<p><strong>How to Export</strong><br>
‘Export-&gt;Custom tabular exporter’. Notice that “source”, “target”, and “Date” are checked in the content tab; uncheck “Date”, as it will not be used in Gephi (networks where the nodes have different dates, ie dynamic networks, are beyond us for the moment). Go to the download tab and change the download option from ‘Tab-separated values (TSV)’ to ‘Comma-separated values (CSV)’ and press download.</p>
<blockquote>
<p>Reflection<br>
Rather than get frustrated, I decided to ask my collegues and contine with the tutorial. The most important part was that I do understand how to use the system, even though the data isn’t 100% correct. Until I get a response, I will redo this part to continue with next week exercises. I still feel pretty good because honestly, I think this week’s felt like the easiest for me and I was about to go over everything fairly smoothly. I didn’t really let the minor error get in the way, and as soon as I redo this, it’ll take me less than half hour to correct so I’m feeling pretty good overall. I will attach everything for the fail log as well.</p>
</blockquote>

</body></html>